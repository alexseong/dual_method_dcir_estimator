# A Dual-Method Framework for DC Internal Resistance Estimation
<p align="center">
Shoban Pujari, Alex Seong<br>
November 2025
</p>

## Abstract
Accurate estimation of dynamic direct current internal resistance (DCIR) in lithium-ion cells remains one of the most critical, yet unresolved, modeling bottlenecks in industrial Battery Management Systems (BMS). Conventional voltage-drop based DCIR estimation ‚Äî while computationally attractive ‚Äî collapses under non‚Äìsteady-state excitation, state-of-charge (SOC) dependent hysteresis, temperature-dependent transport losses, and slow relaxation modes that manifest in multi-time-constant impedance behavior. This paper introduces a **physics-informed hybrid modeling framework** that unifies:<br>
(1) a 2-RC Equivalent Circuit Model (ECM) as a physically interpretable dynamic prior,<br>
(2) a differentiable Runge‚ÄìKutta solver (Neural ODE) to propagate continuous-time electrochemical state trajectories, and<br>
(3) a temperature-aware residual neural network that learns structured unmodeled dynamics (aging, hysteresis, SEI-layer drift, localized diffusion losses).<br>

Unlike conventional ML regressors, the neural component is never tasked with learning the forward dynamics ‚Äúfrom scratch‚Äù; instead it learns only the error manifold **orthogonal to physics**, dramatically improving generalization and identifiability.<br>
We further introduce a Bayesian Kalman filtering layer for online inference ‚Äî allowing parametric DCIR to be tracked in real-time under arbitrary excitation waveforms. Synthetic campaigns and preliminary real-cell validations demonstrate that the hybrid architecture consistently outperforms voltage-drop approaches and pure RK-ECM simulation, particularly in regimes with sharp current steps, high dI/dt, thermal gradients, and low-SOC driving conditions. This establishes a generalizable methodology for cell-level DCIR estimation that scales to real pack operation and aligns directly with the future direction of industrial predictive battery control.

## Nomenclature

| Symbol | Meaning | Units |
|:---:|:---|:---:|
| $$ v_{c1}, v_{c2} $$ | Voltage across first and second RC polarization branches | V |
| $ SOC $ | State of Charge | ‚Äì |
| $ T $ | Cell temperature | ¬∞C (or K) |
| $ I(t) $ | Applied current (positive = charge, negative = discharge) | A |
| $ V(t) $ | Terminal cell voltage | V |
| $ OCV(SOC,T) $ | Open-circuit voltage as function of SOC & temperature | V |
| $ R_0 $ | Instantaneous ohmic resistance | Œ© |
| $ R_1, R_2 $ | Polarization resistances (slow & fast modes) | Œ© |
| $ C_1, C_2 $ | Polarization capacitances (slow & fast modes) | F |
| $ Q $ | Nominal cell capacity | As or Ah |
| $ \eta $ | Coulombic efficiency | ‚Äì |
| $ \dot{x} $ | Time derivative of state vector | (various) |
| $ \hat{V} $ | Model-predicted voltage | V |
| $ \Delta V_\theta $ | Neural-network residual correction | V |
| $ L(\theta) $ | Training loss (voltage domain) | V¬≤ |
| $ F_{RK4}(\cdot) $ | Runge-Kutta 4th-order time propagator | ‚Äì |
| KF | Kalman Filter | ‚Äì |
| DCIR | Direct Current Internal Resistance | Œ© |

## 1. Introduction

Reliable estimation of a lithium-ion cell‚Äôs **DC internal resistance (DCIR)** under real operating conditions is central to modern battery management systems (BMS). DCIR governs instantaneous **power capability**, **heat generation**, and **voltage sag**, thereby affecting **driver-perceived performance** (acceleration, regen), **safety margins** (thermal run-away risk), and **state-of-health** (SOH) diagnostics. In electric vehicles and stationary storage, the estimator must remain **accurate across a wide range of currents**, **temperatures, and states of charge (SOC)**; it must be **computationally light**, **data-efficient**, and **stable** under measurement noise. Meeting all of these simultaneously is difficult because the cell‚Äôs terminal behavior couples fast interfacial phenomena (double-layer charging, SEI, contact resistances) and slow diffusion/transport effects (porous electrode and electrolyte transport), each with different time scales and temperature sensitivities. Any estimator that collapses this multiscale structure into a single lumped constant tends to be biased, especially during transients‚Äîwhich is precisely when the BMS needs accurate predictions. 

Industrial practice often defaults to the Voltage-Drop (current step) method for DCIR: apply a pulse $ \Delta I $ and measure the
corresponding $ \Delta V $; the ratio 
$ ùëÖ_{drop} = \Delta V / \Delta I$ is simple, fast, and explainable. Yet in realistic drive cycles and grid profiles, current rarely remains piecewise constant; polarization dynamics continue to evolve well after the step, temperature may drift during the pulse, and measurement noise can corrupt small $ \Delta V $. As a result, $ ùëÖ_{drop} $ becomes context-dependent: it varies with the exact timing window, pre-conditioning, and the underlying relaxation state. This leads to over-optimism (underestimating sag during a subsequent burst) or over-conservatism (excess thermal derating), both undesirable for energy and power management.

A classical remedy is to adopt Equivalent Circuit Models (ECMs) to explain transients: a series resistance $ùëÖ_0$ in line with one or more $ùëÖùê∂$ branches that represent polarization. The 2RC structure is widely accepted as the minimum realistic representation for automotive-grade cells because it separates a fast time constant (sub-seconds to a few seconds) from a slow one (tens of seconds and beyond). In tests such as HPPC (Hybrid Pulse Power Characterization) or PRBS-like excitation, a single-RC (1RC) model typically fails to reproduce the long-tail relaxation that governs voltage recovery and heat generation, forcing downstream algorithms to ‚Äúlearn‚Äù unphysical corrections. In practice, we also require temperature awareness: $ùëÖ_0,ùëÖ_1,ùëÖ_2$ increase at low $ùëá$ (ionic mobility and conductivity degrade), while $ùê∂_1, ùê∂_2$ and the open-circuit voltage $OCV(SOC)$ exhibit their own temperature and SOC dependencies. These effects are nonlinear and coupled; attempting to track them with fixed parametric laws alone (e.g., pure Arrhenius for every component) can be too rigid, while using a fully black-box neural network discards physics and harms extrapolation and interpretability.

This tension motivates hybrid modeling‚Äîmarrying physics for structure with machine learning for flexibility. In recent years, Neural ODE and physics-informed learning have matured into a practical recipe for such problems: put the known differential equations (the ECM) in the forward pass, integrate them with a differentiable solver (e.g., RK4 at BMS sampling rates), and let a small neural network learn only the residual‚Äîthe part that the physics cannot explain well (hysteresis, aging drift, path dependence, parasitic leakage). This preserves causality and units, keeps parameters positive (through constrained activations), and still grants the estimator enough capacity to fit complex data. Crucially, gradients flow through the integrator and the ECM states, enabling end-to-end training on raw $(ùêº,ùëâ,ùëá)$ trajectories rather than on hand-crafted features.

Beyond modeling fidelity, a production-grade estimator must satisfy operational constraints:

* **Computational economy**: BMS controllers operate on limited hardware at 1‚Äì10 Hz (sometimes higher in sub-modules). An explicit **RK4** step is stable and accurate at these rates for the ECM ODEs, avoiding the cost and implementation complexity of fully adaptive/implicit solvers unless the dynamics are truly stiff.

* **Identifiability under realistic excitation**: On-road or in-field data are not textbook pulses. The estimator should remain well-posed for compound profiles (PRBS, WLTC-like driving, grid cycles) and modest sensor noise. Hybrid models help because physics encodes useful priors; the learning component refines rather than invents dynamics.

* **Robustness to temperature and SOC coverage gaps**: Seasonal climate, pack thermal gradients, and nonuniform SOC distributions imply that training data are imbalanced. Physics-informed structure regularizes the model in underrepresented regions and guards against pathological extrapolation.

* **Traceability**: System engineers and safety teams require explainable read-outs‚Äîfor instance, a time-varying $\hat{R}_0(t)$ that correlates with Voltage-Drop trends and a decomposition of polarization into fast/slow branches. A residual head $ \Delta V_\theta $ should be small and structured, not an opaque correction that dominates the signal.

These realities explain why neither extreme‚Äîpurely heuristic DCIR formulas nor purely black-box deep nets‚Äîoffers a satisfying solution. The former are not transient-correct; the latter are hard to certify and brittle when the duty cycle or temperature range changes. The middle path is to keep the ECM as the backbone and empower it with a **temperature-aware parameterization** and a **residual neural head** trained jointly with the **RK4 integrator**. In this setting:

* The **2RC ECM** enforces physically meaningful states $[v_{c1},v_{c2},SOC]$ and the causal relationship between current and voltage.
* The **parameter head** $g_\theta(SOC, T)$ maps operating conditions to $[\hat{R}_0,\hat{R}_1,\hat{C}_1,\hat{R}_2,\hat{C}_2]$ with positivity constraints, capturing smooth thermal/SOC dependencies that are difficult to hand-encode uniformly across chemistries and aging stages.
* The **residual head** $h_\theta(\cdot)$ outputs $\Delta V_\theta$ to absorb residual nonlinearities (minor hysteresis, sensor bias, pack wiring artifacts) while remaining small in magnitude; this preserves interpretability and transfer across similar cells.
* The **Voltage-Drop** method remains in the loop as a baseline and diagnostic: its estimates provide sanity checks and simple field monitors; departures between $R_{drop}$ and learned $\hat{R}_0$ highlight **transient bias** or **temperature-SOC confounding**.

Finally, there is a practical question of data logistics and reproducibility. Many labs and production test benches produce AVL-style CSV logs containing synchronized current, voltage, per-cell voltages, temperature, and metadata. Our pipeline consumes these logs directly, applies consistent sign conventions (charge-positive in the file vs discharge-positive in modeling), infers or accepts the sampling period $\Delta t$, and executes a single training loop that backpropagates through RK4 and both neural heads. The same codebase generates publication-quality plots (voltage fits, parameter trajectories, SOC evolution, error histograms) and enables ablation studies (1RC vs 2RC, residual ON/OFF, analytic OCV vs lookup). This end-to-end path reduces friction between academic modeling and deployable BMS algorithms.

In summary, today‚Äôs deployment constraints and accuracy requirements argue strongly for a dual-method DCIR framework: keep the Voltage-Drop method for its speed and transparency, and augment it with a Neural ODE estimator‚Äîa temperature-aware 2RC ECM integrated with RK4 and a physics-informed residual neural network‚Äîto recover transient-correct behavior with interpretable, physically constrained parameters. This hybrid approach respects the realities of embedded systems while matching or exceeding the accuracy of far heavier identification procedures. The rest of this paper develops the method in detail, establishes its identifiability and stability properties, and demonstrates its superiority on both synthetic stress tests and real AVL datasets spanning large current excursions, wide SOC ranges, and meaningful temperature variations.

## 2. Literature Review / Related Work
Estimation of DC internal resistance (DCIR) in contemporary lithium-ion cells has gradually evolved into a core topic at the intersection of electrochemistry, control engineering, automotive BMS deployment, diagnostic AI, and scientific machine learning. Although the concept of DC resistance has existed since the earliest days of battery instrumentation, the way in which the community defines, measures, and operationalizes DCIR has changed notably over the past decade due to the convergence of three forces: (i) the electrification of transportation and the dramatic increase in dynamic loading severity, (ii) the rising operational demands placed on BMS logic for safety and performance, and (iii) the shift from laboratory-grade stationary pulse measurements toward in-field measurements taken under uncontrolled vehicle operating conditions. Consequently, the literature landscape has become considerably fragmented across multiple methodological families, each solving slightly different aspects of the same estimation problem, yet none of them individually fully satisfying the requirements for accuracy, robustness, physical interpretability, and real-time deployability in production EVs.

Historically, the industry standard has adopted the voltage-step or voltage-drop DCIR measurement paradigm, in which a commanded current step is applied and the DCIR value is computed directly via the ratio of instantaneous $\Delta V$ over $\Delta I$. This procedure remains institutionalized in HPPC protocols, end-of-line manufacturing tests, and cell grading pipelines because it is fast, intuitive, and computationally trivial. However, numerous studies have shown that voltage-drop DCIR is inherently window-dependent, algorithmically sensitive to transient reaction kinetics, and thermally biased. It does not represent a single intrinsic material resistance, but rather a superposition of multiple time-constant dependent polarization phenomena. Modern cells exhibit dual-scale relaxation: a fast interfacial component often settling within seconds, and a slower diffusion-driven component that may continue evolving for tens of seconds or longer. These two exponentially separated mechanisms directly imply that the DCIR measured through $\Delta V$/$\Delta I$ is fundamentally a functional of the measurement protocol rather than a stable physical property. This problem becomes pronounced at low SOC, cold temperature exposure, and aging ‚Äî precisely the corners where diagnosis is most safety-critical.

To address the window-dependence and protocol sensitivity, the community progressively shifted toward physics-structured estimation based on Equivalent Circuit Models (ECM). Early ECM methods used a single RC branch (1RC) primarily because it was analytically simple and identifiability was manageable. Yet over the past ten years, it has become universally accepted ‚Äî particularly in the automotive literature ‚Äî that at least 2RC is required to reproduce the long-tail relaxation observed in real cells. The multi-time-constant structure embedded in 2RC models more faithfully captures the superposed polarization modes, and thereby yields more stable DCIR estimation when driven by dynamic excitation profiles rather than dedicated pulse windows. ECM research has produced a range of identification algorithms, from recursive least squares to extended Kalman filtering to sliding-mode observers. However, these conventional approaches still rely on globally parametric, fixed-form parametric maps for resistance and capacitance versus temperature and SOC ‚Äî usually linear or Arrhenius-type curve fits. These fixed forms are not expressive enough to handle real, high-dimensional, vehicle-grade operating envelopes where thermal gradients, SOC inhomogeneity, load hysteresis, and surface-film dynamics interact in non-trivial ways. The result is that classical ECM remains interpretable and fast, but cannot adapt to complex dynamic environments without over-regularizing the physics or over-fitting the parametric maps.

On the opposite end of the spectrum from ECM are P2D-style electrochemical models. These models theoretically possess the most physical fidelity, as they explicitly resolve lithium intercalation kinetics, electrolyte concentration gradients, and solid diffusion. Theoretically, DCIR computed from such PDE-based frameworks should be closer to the ‚Äútrue‚Äù internal resistance. However, the computational cost, parameter non-identifiability, requirement for implicit PDE solvers, and lack of robust real-time realizability make these models incompatible with embedded BMS targets ‚Äî particularly when required update rates exceed 10 Hz for multi-module EV packs. Even reduced-order versions such as the Single Particle Model (SPM) cannot be readily deployed for real-time DCIR inference in production EV platforms without model-order reduction or offline trained surrogates.
This tension between physical accuracy and deployment feasibility led to the emergence of ML-based battery models. The early ML literature primarily framed DCIR estimation as a regression task using engineered features extracted from pulse responses, relaxation slopes, or domain-expert-crafted thermal descriptors. While these approaches achieved improved empirical fitting, they remained purely black-box, fundamentally lacked causal constraints, and yield non-physical extrapolation outside the training domain ‚Äî a serious problem because batteries age continuously, environment varies seasonally, and BMS logic must be robust not only to the conditions seen during training, but to unseen corner cases. Certification and interpretability therefore remain open issues.
The most recent wave of literature ‚Äî and the direction this paper follows ‚Äî is the scientific machine learning paradigm: Physics-Informed Neural Networks, Neural ODE frameworks, and hybrid models in which neural networks do not replace the physics but augment it by learning residual dynamics. This class of approaches has reframed the role of machine learning in battery modeling: rather than replacing the ECM entirely, the ECM differential equations themselves become part of the neural forward model. In this framework, 2RC ECM dynamics are integrated explicitly within the forward pass using numerical ODE solvers such as Runge‚ÄìKutta. The neural components are then trained to learn only the parts of the system that the physics cannot express ‚Äî for example nonlinear temperature dependence, state-of-aging effects, and fine-scale deviations not captured by the nominal ECM structure. In effect, the physically-derived ODEs provide structural priors, while neural residual maps fill only the gaps. This hybrid approach has emerged as a synthesis that resolves the long-standing triad of contradictions: it preserves interpretability, controls generalization, and enables deployment. Thus, this scientific machine learning direction ‚Äî neural ODEs + physics-structured ECM + residual networks ‚Äî defines the methodological frontier and provides the conceptual foundation upon which the present study is built.
